{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "aiy_tf_for_poets.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "license"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "license"
      },
      "source": [
        "##### *Copyright 2020 Google LLC*\n",
        "*Licensed under the Apache License, Version 2.0 (the \"License\")*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "rKwqeqWBXANA"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRTa3Ee15WsJ"
      },
      "source": [
        "# Retrain a classification model for AIY Vision Kit (with TF1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaX0smDP7xQY"
      },
      "source": [
        "In this tutorial, we'll use TensorFlow to retrain an image classification model (MobileNet) with a flowers dataset, and convert it into the TensorFlow Lite format that's compatible with the AIY Vision Bonnet (included in the AIY Projects Vision Kit).\n",
        "\n",
        "\n",
        "**Note:** The scripts used in this tutorial depend on TensorFlow 1.7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viewin-badges"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scottamain/aiyprojects-raspbian/blob/colab/tutorials/vision/aiy_tf_for_poets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"></a>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<a href=\"https://github.com/scottamain/aiyprojects-raspbian/blob/colab/tutorials/vision/aiy_tf_for_poets.ipynb\" target=\"_parent\"><img src=\"https://img.shields.io/static/v1?logo=GitHub&label=&color=333333&style=flat&message=View%20on%20GitHub\" alt=\"View in GitHub\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnSreNhbCQ69"
      },
      "source": [
        "To start running all the code in this tutorial, select **Runtime > Run all** in the Colab toolbar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTCYQg_be8C0"
      },
      "source": [
        "## Import the required libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZBTCYDICwOG"
      },
      "source": [
        "First, we need to uninstall the version of TensorFlow that's included with Google Colab by default, and replace it with TensorFlow 1.7, as required by the following training scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ms7m4MAPZ1R"
      },
      "source": [
        "! pip uninstall tensorflow tensorboard -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLjaKNp9inlt"
      },
      "source": [
        "! pip install -I absl-py==0.9 jupyter-client==6.1.5 tornado==5.1.0 folium==0.2.1 imgaug==0.2.5 tensorflow==1.7 tensorboard==1.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBMcobPHdD8O"
      },
      "source": [
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('1.7')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v77rlkCKW0IJ"
      },
      "source": [
        "## Prepare the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4QOy2uA3P_p"
      },
      "source": [
        "First let's download and organize the flowers dataset we'll use to retrain the model (it contains 5 flower classes).\n",
        "\n",
        "Pay attention to this part so you can reproduce it with your own images dataset. In particular, notice that the \"flower_photos\" directory contains an appropriately-named directory for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9pYqideeXiI"
      },
      "source": [
        "! git clone https://github.com/googlecodelabs/tensorflow-for-poets-2\n",
        "\n",
        "%cd tensorflow-for-poets-2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUJ1OqRmeusy"
      },
      "source": [
        "! curl http://download.tensorflow.org/example_images/flower_photos.tgz | tar xz -C tf_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CMEbPWIfJiA"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eht5rTouezfK"
      },
      "source": [
        "! ls tf_files/flower_photos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivlTO8t7jNuG"
      },
      "source": [
        "## Retrain the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUccBS9hjZGK"
      },
      "source": [
        "First specify the input image size (this is for both width and height; the model's input expects a square image) and depth multiplier for the MobileNet model. \n",
        "\n",
        "Based on our testing, the only variations compatible with the Vision Bonnet's ML accelerator are the following:\n",
        "\n",
        "+ Input size = 160x160, and depth multiplier = 0.5\n",
        "+ Input size = 192x192, and depth multiplier = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry4wxq4be0yR"
      },
      "source": [
        "IMAGE_SIZE='160'\n",
        "MULTIPLIER='0.50'\n",
        "%env ARCHITECTURE=mobilenet_{MULTIPLIER}_{IMAGE_SIZE}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv6FbY2llOs9"
      },
      "source": [
        "Then start training:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCJOZvfyf6HH"
      },
      "source": [
        "! python -m scripts.retrain \\\n",
        "  --bottleneck_dir=tf_files/bottlenecks \\\n",
        "  --how_many_training_steps=500 \\\n",
        "  --model_dir=tf_files/models/ \\\n",
        "  --summaries_dir=tf_files/training_summaries/$ARCHITECTURE \\\n",
        "  --output_graph=tf_files/retrained_graph.pb \\\n",
        "  --output_labels=tf_files/retrained_labels.txt \\\n",
        "  --architecture=$ARCHITECTURE \\\n",
        "  --image_dir=tf_files/flower_photos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpD2eEErpgiY"
      },
      "source": [
        "## Compile the model for the Vision Kit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhOzAdzF3Dyk"
      },
      "source": [
        "The training script above creates a TensorFlow Lite model that you can run on a CPU, but we want to run this on the AIY Vision Bonnet's ML accelerator (the Myriad 2450). So we need to compile the model for that chip.\n",
        "\n",
        "First download the Vision Bonnet model compiler:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6ZpWgrk21Ad"
      },
      "source": [
        "! curl -LO https://dl.google.com/dl/aiyprojects/vision/bonnet_model_compiler_latest.tgz\t\n",
        "\n",
        "! tar -xzf bonnet_model_compiler_latest.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtPcYiER3Ymp"
      },
      "source": [
        "Then compile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV5fLSQlh4qf"
      },
      "source": [
        "! ./bonnet_model_compiler.par \\\n",
        "  --frozen_graph_path=tf_files/retrained_graph.pb \\\n",
        "  --output_graph_path=tf_files/retrained_graph.binaryproto \\\n",
        "  --input_tensor_name=input \\\n",
        "  --output_tensor_names=final_result \\\n",
        "  --input_tensor_size=160 \\\n",
        "  --debug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R8JMQc1MMm5"
      },
      "source": [
        "Don't worry if you see an error like this:\n",
        "`Check failed: toco::port::file::GetContents(FLAGS_frozen_graph_path, &frozen_graph_contents, toco::port::file::Options()) .ok()`\n",
        "That can happen if the compiler tried requesting the model file before Colab was done saving it from the previous step. So just click the Play button in the above code to run it again. It should work this time.\n",
        "\n",
        "That's it. Your retrained model is ready to run on the Vision Kit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi9-Voc8A7VK"
      },
      "source": [
        "## Download the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiugMm-jBbWl"
      },
      "source": [
        "\n",
        "The compiled model is saved into this Colab runtime's temporary storage. You can download it as follows:\n",
        "\n",
        "1. Open the **Files** tab in the left panel.\n",
        "2. Expand the **tensorflow-for-poets-2** folder and then the **tf_files** folder.\n",
        "3. Right-click on `retrained_graph.binaryproto` and select **Download**.\n",
        "4. Also download `retrained_labels.txt`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TZTwG7nhm0C"
      },
      "source": [
        "## Run the model on the Vision Kit\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwywT4ZpQjLf"
      },
      "source": [
        "You can now run the model on your Coral device with acceleration on the Edge TPU.\n",
        "\n",
        "To get started, try using [this code for image classification with the TensorFlow Lite API](https://github.com/google-coral/tflite/tree/master/python/examples/classification). Just follow the instructions on that page to set up your device, copy the `mobilenet_v2_1.0_224_quant_edgetpu.tflite` and `flower_labels.txt` files to your Coral Dev Board or device with a Coral Accelerator, and pass it a flower photo like this:\n",
        "\n",
        "```\n",
        "python3 classify_image.py \\\n",
        "  --model mobilenet_v2_1.0_224_quant_edgetpu.tflite \\\n",
        "  --labels flower_labels.txt \\\n",
        "  --input flower.jpg\n",
        "```\n",
        "\n",
        "Check out more examples for running inference at [coral.ai/examples](https://coral.ai/examples/#code-examples/)."
      ]
    }
  ]
}